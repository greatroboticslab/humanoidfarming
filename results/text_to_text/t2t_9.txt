[DEBUG] mode= t2t vlm= Qwen/Qwen2.5-VL-7B-Instruct
>>> system
You are a helpful assistant.
user
How do LLMs generate text?
assistant
Large Language Models (LLMs) generate text by processing input data, which can be plain text or other forms of data like images and audio. The process typically involves the following steps:

1. **Training**: 
   - **Data Collection**: LLMs are trained on vast amounts of text data, such as books, articles, websites, and other written content.
   - **Data Preprocessing**: The collected text is cleaned and formatted to remove noise. This includes removing punctuation, converting to lowercase, splitting sentences into words, etc.
   - **Model Architecture**: The text data is fed into a neural network model, which is specifically designed for language tasks. Common architectures include transformers, such as those used in models like BERT, GPT, and T5.

2. **Prediction**
